#!/usr/bin/env python3
"""
æ™ºèƒ½åˆ†æå”èª¿å™¨
æ•´åˆæ‰€æœ‰åˆ†æå·¥å…·ï¼Œæä¾›æ™ºèƒ½åŒ–çš„ç´„ç‘Ÿå¤«æ£®çµæ•¸æ“šåˆ†ææµç¨‹
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import json
import subprocess
import sys
from datetime import datetime
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šmatplotlib
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('seaborn-v0_8')

class IntelligentAnalysisCoordinator:
    """
    æ™ºèƒ½åˆ†æå”èª¿å™¨
    è‡ªå‹•é¸æ“‡æœ€é©åˆçš„åˆ†ææ–¹æ³•ä¸¦åŸ·è¡Œå®Œæ•´çš„åˆ†ææµç¨‹
    """
    
    def __init__(self, base_dir=None):
        if base_dir is None:
            self.base_dir = Path("/Users/albert-mac/Code/GitHub/Josephson")
        else:
            self.base_dir = Path(base_dir)
            
        self.exp_data_dir = self.base_dir / "data" / "experimental"
        self.sim_data_dir = self.base_dir / "data" / "simulated"
        self.advanced_sim_dir = self.base_dir / "data" / "simulated" / "advanced"
        self.results_dir = self.base_dir / "results"
        self.examples_dir = self.base_dir / "examples"
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.advanced_sim_dir.mkdir(parents=True, exist_ok=True)
        self.results_dir.mkdir(exist_ok=True)
        
        self.analysis_history = []
        self.current_best_correlations = {}
    
    def assess_data_quality(self):
        """
        è©•ä¼°å¯¦é©—æ•¸æ“šå“è³ª
        """
        print("ğŸ” è©•ä¼°å¯¦é©—æ•¸æ“šå“è³ª...")
        
        data_quality = {}
        
        for exp_file in self.exp_data_dir.glob("*.csv"):
            try:
                data = pd.read_csv(exp_file)
                
                if 'y_field' in data.columns and 'Ic' in data.columns:
                    y_field = data['y_field'].values
                    Ic = data['Ic'].values
                    
                    quality_metrics = {
                        'n_points': len(data),
                        'field_range': np.ptp(y_field),
                        'current_range': np.ptp(Ic),
                        'snr_estimate': np.mean(Ic) / np.std(Ic),
                        'missing_values': data.isnull().sum().sum(),
                        'cv': np.std(Ic) / np.mean(Ic),
                        'monotonicity': self._assess_monotonicity(y_field),
                        'periodicity_strength': self._assess_periodicity(Ic)
                    }
                    
                    # ç¸½é«”å“è³ªè©•åˆ† (0-100)
                    quality_score = self._calculate_quality_score(quality_metrics)
                    quality_metrics['quality_score'] = quality_score
                    
                    data_quality[exp_file.name] = quality_metrics
                    
                    print(f"   {exp_file.name}: å“è³ªè©•åˆ† {quality_score:.1f}/100")
                    
            except Exception as e:
                print(f"âŒ è©•ä¼° {exp_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                data_quality[exp_file.name] = {'error': str(e)}
        
        return data_quality
    
    def _assess_monotonicity(self, y_field):
        """è©•ä¼°ç£å ´æ•¸æ“šçš„å–®èª¿æ€§"""
        if len(y_field) < 2:
            return 0.0
        
        diff = np.diff(y_field)
        if np.all(diff > 0):
            return 1.0  # å®Œå…¨éå¢
        elif np.all(diff < 0):
            return 1.0  # å®Œå…¨éæ¸›
        else:
            # è¨ˆç®—å–®èª¿æ€§æ¯”ä¾‹
            consistent_direction = max(np.sum(diff > 0), np.sum(diff < 0))
            return consistent_direction / len(diff)
    
    def _assess_periodicity(self, Ic):
        """è©•ä¼°é›»æµæ•¸æ“šçš„é€±æœŸæ€§å¼·åº¦"""
        if len(Ic) < 10:
            return 0.0
        
        # è‡ªç›¸é—œåˆ†æ
        Ic_centered = Ic - np.mean(Ic)
        autocorr = np.correlate(Ic_centered, Ic_centered, mode='full')
        autocorr = autocorr[autocorr.size // 2:]
        autocorr = autocorr / autocorr[0]
        
        # å°‹æ‰¾ç¬¬ä¸€å€‹é¡¯è‘—çš„å±€éƒ¨æœ€å¤§å€¼
        for i in range(2, min(len(autocorr) - 2, len(Ic) // 4)):
            if (autocorr[i] > autocorr[i-1] and autocorr[i] > autocorr[i+1] and 
                autocorr[i] > 0.1):
                return autocorr[i]
        
        return 0.0
    
    def _calculate_quality_score(self, metrics):
        """è¨ˆç®—æ•¸æ“šå“è³ªç¶œåˆè©•åˆ†"""
        score = 0
        
        # æ•¸æ“šé»æ•¸è©•åˆ† (0-20åˆ†)
        if metrics['n_points'] >= 100:
            score += 20
        elif metrics['n_points'] >= 50:
            score += 15
        elif metrics['n_points'] >= 20:
            score += 10
        else:
            score += 5
        
        # ä¿¡å™ªæ¯”è©•åˆ† (0-25åˆ†)
        snr = metrics['snr_estimate']
        if snr >= 10:
            score += 25
        elif snr >= 5:
            score += 20
        elif snr >= 2:
            score += 15
        else:
            score += max(0, snr * 5)
        
        # å–®èª¿æ€§è©•åˆ† (0-15åˆ†)
        score += metrics['monotonicity'] * 15
        
        # é€±æœŸæ€§è©•åˆ† (0-20åˆ†)
        score += metrics['periodicity_strength'] * 20
        
        # è®Šç•°ä¿‚æ•¸è©•åˆ† (0-10åˆ†) - é©ç•¶çš„è®Šç•°æ˜¯å¥½çš„
        cv = metrics['cv']
        if 0.1 <= cv <= 0.5:
            score += 10
        elif 0.05 <= cv <= 0.8:
            score += 8
        else:
            score += max(0, 10 - abs(cv - 0.3) * 10)
        
        # ç¼ºå¤±å€¼æ‡²ç½° (0-10åˆ†)
        if metrics['missing_values'] == 0:
            score += 10
        else:
            score += max(0, 10 - metrics['missing_values'])
        
        return min(100, score)
    
    def select_optimal_analysis_strategy(self, data_quality):
        """
        æ ¹æ“šæ•¸æ“šå“è³ªé¸æ“‡æœ€ä½³åˆ†æç­–ç•¥
        """
        print("\nğŸ¯ é¸æ“‡æœ€ä½³åˆ†æç­–ç•¥...")
        
        strategies = {}
        
        for filename, quality in data_quality.items():
            if 'error' in quality:
                strategies[filename] = 'skip'
                continue
                
            score = quality['quality_score']
            n_points = quality['n_points']
            snr = quality['snr_estimate']
            periodicity = quality['periodicity_strength']
            
            if score >= 80:
                # é«˜å“è³ªæ•¸æ“šï¼šä½¿ç”¨æ‰€æœ‰é€²éšæ–¹æ³•
                strategy = 'comprehensive_advanced'
            elif score >= 60:
                # ä¸­ç­‰å“è³ªæ•¸æ“šï¼šä½¿ç”¨æ¨™æº–é€²éšæ–¹æ³•
                strategy = 'standard_advanced'
            elif score >= 40:
                # ä½å“è³ªæ•¸æ“šï¼šä½¿ç”¨åŸºç¤æ–¹æ³•åŠ æ”¹é€²
                strategy = 'basic_improved'
            else:
                # æ¥µä½å“è³ªæ•¸æ“šï¼šåƒ…åŸºç¤åˆ†æ
                strategy = 'basic_only'
            
            # ç‰¹æ®Šæƒ…æ³èª¿æ•´
            if n_points < 30:
                strategy = 'basic_only'
            elif snr < 2:
                strategy = max('basic_improved', strategy)
            elif periodicity > 0.5:
                # å¼·é€±æœŸæ€§ï¼Œé©åˆé€²éšåˆ†æ
                if strategy == 'basic_only':
                    strategy = 'basic_improved'
            
            strategies[filename] = strategy
            print(f"   {filename}: {strategy} (å“è³ªè©•åˆ†: {score:.1f})")
        
        return strategies
    
    def execute_analysis_pipeline(self, strategies):
        """
        åŸ·è¡Œå®Œæ•´çš„åˆ†æç®¡é“
        """
        print("\nğŸš€ åŸ·è¡Œåˆ†æç®¡é“...")
        
        pipeline_results = {}
        
        # ç¬¬ä¸€éšæ®µï¼šåŸºç¤å’Œæ”¹é€²æ¨¡æ“¬
        print("\nğŸ“Š ç¬¬ä¸€éšæ®µï¼šåŸºç¤æ¨¡æ“¬æ•¸æ“šç”Ÿæˆ...")
        basic_results = self._run_basic_simulation()
        
        # ç¬¬äºŒéšæ®µï¼šæ©Ÿå™¨å­¸ç¿’å„ªåŒ– (é‡å°ä¸­é«˜å“è³ªæ•¸æ“š)
        ml_candidates = [f for f, s in strategies.items() 
                        if s in ['standard_advanced', 'comprehensive_advanced']]
        
        if ml_candidates:
            print("\nğŸ¤– ç¬¬äºŒéšæ®µï¼šæ©Ÿå™¨å­¸ç¿’å„ªåŒ–...")
            ml_results = self._run_ml_optimization(ml_candidates)
            pipeline_results['ml_optimization'] = ml_results
        
        # ç¬¬ä¸‰éšæ®µï¼šé€²éšç‰©ç†æ¨¡å‹ (é‡å°é«˜å“è³ªæ•¸æ“š)
        physics_candidates = [f for f, s in strategies.items() 
                            if s == 'comprehensive_advanced']
        
        if physics_candidates:
            print("\nğŸ”¬ ç¬¬ä¸‰éšæ®µï¼šé€²éšç‰©ç†æ¨¡å‹...")
            physics_results = self._run_advanced_physics(physics_candidates)
            pipeline_results['advanced_physics'] = physics_results
        
        # ç¬¬å››éšæ®µï¼šæ·±åº¦åˆ†æå’Œå¯è¦–åŒ–
        print("\nğŸ“ˆ ç¬¬å››éšæ®µï¼šæ·±åº¦åˆ†æå’Œå¯è¦–åŒ–...")
        visualization_results = self._run_comprehensive_visualization()
        pipeline_results['visualization'] = visualization_results
        
        return pipeline_results
    
    def _run_basic_simulation(self):
        """é‹è¡ŒåŸºç¤æ¨¡æ“¬"""
        try:
            script_path = self.examples_dir / "generate_improved_simulation.py"
            if script_path.exists():
                result = subprocess.run([sys.executable, str(script_path)], 
                                      capture_output=True, text=True, cwd=str(self.base_dir))
                return {'success': result.returncode == 0, 'output': result.stdout, 'error': result.stderr}
            else:
                return {'success': False, 'error': 'Script not found'}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _run_ml_optimization(self, candidates):
        """é‹è¡Œæ©Ÿå™¨å­¸ç¿’å„ªåŒ–"""
        try:
            script_path = self.examples_dir / "advanced_ml_optimization.py"
            if script_path.exists():
                result = subprocess.run([sys.executable, str(script_path)], 
                                      capture_output=True, text=True, cwd=str(self.base_dir))
                return {'success': result.returncode == 0, 'output': result.stdout, 'error': result.stderr}
            else:
                return {'success': False, 'error': 'ML script not found'}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _run_advanced_physics(self, candidates):
        """é‹è¡Œé€²éšç‰©ç†æ¨¡å‹"""
        try:
            script_path = self.examples_dir / "advanced_physics_modeling.py"
            if script_path.exists():
                result = subprocess.run([sys.executable, str(script_path)], 
                                      capture_output=True, text=True, cwd=str(self.base_dir))
                return {'success': result.returncode == 0, 'output': result.stdout, 'error': result.stderr}
            else:
                return {'success': False, 'error': 'Physics script not found'}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def _run_comprehensive_visualization(self):
        """é‹è¡Œç¶œåˆå¯è¦–åŒ–"""
        try:
            script_path = self.examples_dir / "simple_deep_analysis.py"
            if script_path.exists():
                result = subprocess.run([sys.executable, str(script_path)], 
                                      capture_output=True, text=True, cwd=str(self.base_dir))
                return {'success': result.returncode == 0, 'output': result.stdout, 'error': result.stderr}
            else:
                return {'success': False, 'error': 'Visualization script not found'}
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def evaluate_final_results(self):
        """
        è©•ä¼°æœ€çµ‚çµæœä¸¦é¸æ“‡æœ€ä½³æ¨¡å‹
        """
        print("\nğŸ“Š è©•ä¼°æœ€çµ‚çµæœ...")
        
        final_evaluation = {}
        
        # æ”¶é›†æ‰€æœ‰å¯ç”¨çš„çµæœæ–‡ä»¶
        result_files = {
            'basic': self.results_dir / "improved_simulation_results.json",
            'ml': self.results_dir / "ml_optimized_parameters.json",
            'advanced': self.results_dir / "advanced_simulation_results.json"
        }
        
        for method, file_path in result_files.items():
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    final_evaluation[method] = data
                except Exception as e:
                    print(f"âŒ è¼‰å…¥ {method} çµæœå¤±æ•—: {e}")
        
        # æ¯”è¼ƒæ‰€æœ‰æ–¹æ³•çš„æ€§èƒ½
        performance_summary = self._compare_all_methods(final_evaluation)
        
        # ç”Ÿæˆæœ€çµ‚å»ºè­°
        recommendations = self._generate_recommendations(performance_summary)
        
        return {
            'performance_summary': performance_summary,
            'recommendations': recommendations,
            'final_evaluation': final_evaluation
        }
    
    def _compare_all_methods(self, evaluation_data):
        """æ¯”è¼ƒæ‰€æœ‰æ–¹æ³•çš„æ€§èƒ½"""
        comparison = {}
        
        for exp_file in self.exp_data_dir.glob("*.csv"):
            filename = exp_file.name
            comparison[filename] = {}
            
            # è¼‰å…¥å¯¦é©—æ•¸æ“š
            try:
                exp_data = pd.read_csv(exp_file)
                exp_Ic = exp_data['Ic'].values
                
                # æ¯”è¼ƒä¸åŒæ–¹æ³•
                for method in ['basic', 'advanced']:
                    sim_file = None
                    
                    if method == 'basic':
                        sim_file = self.sim_data_dir / f"improved_sim_{filename}"
                    elif method == 'advanced':
                        sim_file = self.advanced_sim_dir / f"advanced_sim_{filename}"
                    
                    if sim_file and sim_file.exists():
                        sim_data = pd.read_csv(sim_file)
                        sim_Ic = sim_data['Ic'].values
                        
                        # è¨ˆç®—ç›¸é—œä¿‚æ•¸
                        correlation, p_value = pearsonr(exp_Ic, sim_Ic)
                        
                        comparison[filename][method] = {
                            'correlation': correlation,
                            'p_value': p_value,
                            'available': True
                        }
                    else:
                        comparison[filename][method] = {'available': False}
                        
            except Exception as e:
                print(f"âŒ æ¯”è¼ƒ {filename} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        return comparison
    
    def _generate_recommendations(self, performance_summary):
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []
        
        # åˆ†ææ•´é«”æ€§èƒ½
        all_correlations = []
        best_method_counts = {}
        
        for filename, methods in performance_summary.items():
            available_methods = {k: v for k, v in methods.items() if v.get('available', False)}
            
            if available_methods:
                best_method = max(available_methods.keys(), 
                                key=lambda k: available_methods[k]['correlation'])
                best_method_counts[best_method] = best_method_counts.get(best_method, 0) + 1
                
                for method, result in available_methods.items():
                    all_correlations.append(result['correlation'])
        
        avg_correlation = np.mean(all_correlations) if all_correlations else 0
        
        # ç”Ÿæˆå…·é«”å»ºè­°
        if avg_correlation < 0.2:
            recommendations.append("ğŸ”§ å»ºè­°é–‹ç™¼æ›´ç²¾ç¢ºçš„ç‰©ç†æ¨¡å‹ï¼Œè€ƒæ…®å™¨ä»¶ç‰¹å®šæ•ˆæ‡‰")
            recommendations.append("ğŸ“Š å»ºè­°æ”¶é›†æ›´å¤šå¯¦é©—æ•¸æ“šä»¥æ”¹å–„æ¨¡å‹è¨“ç·´")
            
        if avg_correlation < 0.1:
            recommendations.append("âš ï¸  ç•¶å‰æ¨¡å‹èˆ‡å¯¦é©—æ•¸æ“šç›¸é—œæ€§è¼ƒä½ï¼Œå»ºè­°é‡æ–°æª¢æŸ¥å¯¦é©—è¨­ç½®")
            
        if best_method_counts:
            best_overall = max(best_method_counts.keys(), key=lambda k: best_method_counts[k])
            recommendations.append(f"ğŸ† æ¨è–¦ä½¿ç”¨ {best_overall} æ–¹æ³•ï¼ˆåœ¨ {best_method_counts[best_overall]} å€‹æª”æ¡ˆä¸­è¡¨ç¾æœ€ä½³ï¼‰")
        
        recommendations.append("ğŸ”¬ å»ºè­°é€²è¡Œæº«åº¦ç›¸é—œæ€§ç ”ç©¶ä»¥æ”¹å–„æ¨¡å‹æº–ç¢ºæ€§")
        recommendations.append("ğŸ¯ å»ºè­°å¯¦æ–½å¯¦æ™‚åƒæ•¸å„ªåŒ–ç³»çµ±")
        
        return recommendations
    
    def generate_comprehensive_report(self, data_quality, strategies, pipeline_results, final_results):
        """
        ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š
        """
        report_path = self.results_dir / "comprehensive_analysis_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ç´„ç‘Ÿå¤«æ£®çµæ•¸æ“šæ™ºèƒ½åˆ†æç¶œåˆå ±å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
            
            # æ•¸æ“šå“è³ªè©•ä¼°
            f.write("## 1. æ•¸æ“šå“è³ªè©•ä¼°\n\n")
            quality_scores = [q.get('quality_score', 0) for q in data_quality.values() if 'quality_score' in q]
            if quality_scores:
                f.write(f"- **å¹³å‡å“è³ªè©•åˆ†**: {np.mean(quality_scores):.1f}/100\n")
                f.write(f"- **æœ€é«˜å“è³ªè©•åˆ†**: {np.max(quality_scores):.1f}/100\n")
                f.write(f"- **æœ€ä½å“è³ªè©•åˆ†**: {np.min(quality_scores):.1f}/100\n\n")
                
                f.write("### å„æª”æ¡ˆå“è³ªè©•åˆ†:\n")
                for filename, quality in data_quality.items():
                    if 'quality_score' in quality:
                        f.write(f"- {filename}: {quality['quality_score']:.1f}/100\n")
                f.write("\n")
            
            # åˆ†æç­–ç•¥
            f.write("## 2. åˆ†æç­–ç•¥é¸æ“‡\n\n")
            strategy_counts = {}
            for strategy in strategies.values():
                strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
            
            for strategy, count in strategy_counts.items():
                f.write(f"- **{strategy}**: {count} å€‹æª”æ¡ˆ\n")
            f.write("\n")
            
            # åˆ†æçµæœ
            f.write("## 3. åˆ†æçµæœæ‘˜è¦\n\n")
            performance = final_results.get('performance_summary', {})
            
            if performance:
                all_basic_corr = []
                all_advanced_corr = []
                
                for filename, methods in performance.items():
                    if methods.get('basic', {}).get('available', False):
                        all_basic_corr.append(methods['basic']['correlation'])
                    if methods.get('advanced', {}).get('available', False):
                        all_advanced_corr.append(methods['advanced']['correlation'])
                
                if all_basic_corr:
                    f.write(f"- **åŸºç¤æ¨¡å‹å¹³å‡ç›¸é—œä¿‚æ•¸**: {np.mean(all_basic_corr):.4f}\n")
                if all_advanced_corr:
                    f.write(f"- **é€²éšæ¨¡å‹å¹³å‡ç›¸é—œä¿‚æ•¸**: {np.mean(all_advanced_corr):.4f}\n")
                
                if all_basic_corr and all_advanced_corr:
                    improvement = np.mean(all_advanced_corr) - np.mean(all_basic_corr)
                    f.write(f"- **é€²éšæ¨¡å‹æ”¹é€²åº¦**: {improvement:.4f}\n")
                f.write("\n")
            
            # å»ºè­°
            f.write("## 4. æ”¹é€²å»ºè­°\n\n")
            recommendations = final_results.get('recommendations', [])
            for i, rec in enumerate(recommendations, 1):
                f.write(f"{i}. {rec}\n")
            f.write("\n")
            
            # æŠ€è¡“ç´°ç¯€
            f.write("## 5. æŠ€è¡“å¯¦æ–½ç´°ç¯€\n\n")
            f.write("### å·²å¯¦æ–½çš„æ–¹æ³•:\n")
            f.write("- âœ… åŸºç¤ç´„ç‘Ÿå¤«æ£®çµæ¨¡æ“¬\n")
            f.write("- âœ… åƒæ•¸å„ªåŒ–ç®—æ³•\n")
            f.write("- âœ… æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µæå–\n")
            f.write("- âœ… é€²éšç‰©ç†æ¨¡å‹ï¼ˆæº«åº¦æ•ˆæ‡‰ã€éç·šæ€§é …ï¼‰\n")
            f.write("- âœ… æ™ºèƒ½åˆ†ææµç¨‹\n")
            f.write("- âœ… ç¶œåˆæ€§èƒ½è©•ä¼°\n\n")
            
            f.write("### ä¸‹ä¸€æ­¥ç™¼å±•æ–¹å‘:\n")
            f.write("- ğŸ”„ å¯¦æ™‚åƒæ•¸èª¿æ•´ç³»çµ±\n")
            f.write("- ğŸ§  æ·±åº¦å­¸ç¿’æ¨¡å‹\n")
            f.write("- ğŸŒ¡ï¸ å¤šæº«åº¦é»å»ºæ¨¡\n")
            f.write("- ğŸ“ å™¨ä»¶å¹¾ä½•å„ªåŒ–\n")
            f.write("- ğŸ”— å¤šçµå™¨ä»¶å»ºæ¨¡\n")
        
        print(f"âœ… ç¶œåˆå ±å‘Šå·²ä¿å­˜è‡³: {report_path}")
        return report_path

def main():
    """
    ä¸»åŸ·è¡Œå‡½æ•¸
    """
    print("ğŸ§  === æ™ºèƒ½ç´„ç‘Ÿå¤«æ£®çµæ•¸æ“šåˆ†æç³»çµ± ===\n")
    
    # å‰µå»ºå”èª¿å™¨
    coordinator = IntelligentAnalysisCoordinator()
    
    # ç¬¬ä¸€æ­¥ï¼šè©•ä¼°æ•¸æ“šå“è³ª
    data_quality = coordinator.assess_data_quality()
    
    # ç¬¬äºŒæ­¥ï¼šé¸æ“‡åˆ†æç­–ç•¥
    strategies = coordinator.select_optimal_analysis_strategy(data_quality)
    
    # ç¬¬ä¸‰æ­¥ï¼šåŸ·è¡Œåˆ†æç®¡é“
    pipeline_results = coordinator.execute_analysis_pipeline(strategies)
    
    # ç¬¬å››æ­¥ï¼šè©•ä¼°æœ€çµ‚çµæœ
    final_results = coordinator.evaluate_final_results()
    
    # ç¬¬äº”æ­¥ï¼šç”Ÿæˆç¶œåˆå ±å‘Š
    report_path = coordinator.generate_comprehensive_report(
        data_quality, strategies, pipeline_results, final_results
    )
    
    print(f"\nğŸ‰ æ™ºèƒ½åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š ç¶œåˆå ±å‘Š: {report_path}")
    print(f"ğŸ“ˆ å»ºè­°æŸ¥çœ‹çµæœç›®éŒ„: {coordinator.results_dir}")
    
    # é¡¯ç¤ºé—œéµçµæœæ‘˜è¦
    print(f"\nğŸ“‹ é—œéµçµæœæ‘˜è¦:")
    recommendations = final_results.get('recommendations', [])
    for i, rec in enumerate(recommendations[:3], 1):
        print(f"   {i}. {rec}")
    
    if len(recommendations) > 3:
        print(f"   ... æ›´å¤šå»ºè­°è«‹æŸ¥çœ‹å®Œæ•´å ±å‘Š")

if __name__ == "__main__":
    main()
