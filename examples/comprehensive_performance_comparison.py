#!/usr/bin/env python3
"""
ç¶œåˆæ€§èƒ½æ¯”è¼ƒå·¥å…·ï¼šæ¯”è¼ƒæ‰€æœ‰åˆ†ææ–¹æ³•çš„æ•ˆæœ
Comprehensive Performance Comparison Tool
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import json
from scipy.stats import pearsonr
from datetime import datetime
import seaborn as sns

# Configure matplotlib with English fonts only
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('seaborn-v0_8')
plt.rcParams['font.size'] = 10
plt.rcParams['figure.dpi'] = 100

class ComprehensiveComparator:
    """ç¶œåˆæ€§èƒ½æ¯”è¼ƒå™¨"""
    
    def __init__(self, base_dir):
        self.base_dir = Path(base_dir)
        self.exp_dir = self.base_dir / "data" / "experimental"
        self.sim_dir = self.base_dir / "data" / "simulated"
        self.advanced_sim_dir = self.sim_dir / "advanced"
        self.results_dir = self.base_dir / "results"
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.advanced_sim_dir.mkdir(parents=True, exist_ok=True)
        self.results_dir.mkdir(exist_ok=True)
        
        # è¼‰å…¥æ‰€æœ‰çµæœ
        self.basic_results = self._load_json_results("improved_simulation_results.json")
        self.advanced_results = self._load_json_results("advanced_simulation_results.json")
        self.ml_params = self._load_json_results("ml_optimized_parameters.json")
        
    def _load_json_results(self, filename):
        """è¼‰å…¥JSONçµæœæª”æ¡ˆ"""
        filepath = self.results_dir / filename
        if filepath.exists():
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def calculate_correlations_with_ml_params(self):
        """ä½¿ç”¨MLå„ªåŒ–åƒæ•¸è¨ˆç®—ç›¸é—œä¿‚æ•¸"""
        print("ğŸ¤– ä½¿ç”¨MLå„ªåŒ–åƒæ•¸è¨ˆç®—ç›¸é—œä¿‚æ•¸...")
        
        ml_correlations = {}
        
        for filename, params in self.ml_params.items():
            exp_file = self.exp_dir / filename
            if not exp_file.exists():
                continue
                
            try:
                # è¼‰å…¥å¯¦é©—æ•¸æ“š
                exp_data = pd.read_csv(exp_file)
                exp_y = exp_data['y_field'].values
                exp_Ic = exp_data['Ic'].values
                
                # ä½¿ç”¨MLå„ªåŒ–åƒæ•¸ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š
                sim_Ic = self._generate_ml_simulation(exp_y, params)
                
                # è¨ˆç®—ç›¸é—œä¿‚æ•¸
                correlation, p_value = pearsonr(exp_Ic, sim_Ic)
                
                ml_correlations[filename] = {
                    'correlation': correlation,
                    'p_value': p_value,
                    'parameters': params
                }
                
                print(f"   âœ… {filename}: r = {correlation:.4f}")
                
            except Exception as e:
                print(f"   âŒ {filename}: éŒ¯èª¤ - {e}")
                ml_correlations[filename] = {
                    'correlation': np.nan,
                    'p_value': np.nan,
                    'error': str(e)
                }
        
        return ml_correlations
    
    def _generate_ml_simulation(self, y_field, params):
        """ä½¿ç”¨MLåƒæ•¸ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š"""
        flux_quantum = 2.067e-15
        phi_ext = y_field * params['field_scale']
        normalized_flux = np.pi * phi_ext / flux_quantum
        
        with np.errstate(divide='ignore', invalid='ignore'):
            sinc_term = np.sin(normalized_flux + params['phase_offset']) / (normalized_flux + 1e-10)
            sinc_term = np.where(np.abs(normalized_flux) < 1e-10, 1.0, sinc_term)
        
        pattern = np.abs(sinc_term) * (1 + params['asymmetry'] * np.cos(2 * normalized_flux))
        sim_Ic = params['Ic_base'] * pattern
        
        # æ·»åŠ å™ªè²
        if 'noise_level' in params:
            noise = np.random.normal(0, params['noise_level'], len(sim_Ic))
            sim_Ic += noise
            
        return sim_Ic
    
    def create_comprehensive_comparison(self):
        """å‰µå»ºç¶œåˆæ¯”è¼ƒåˆ†æ"""
        print("\nğŸ“Š å‰µå»ºç¶œåˆæ€§èƒ½æ¯”è¼ƒ...")
        
        # è¨ˆç®—MLç›¸é—œä¿‚æ•¸
        ml_correlations = self.calculate_correlations_with_ml_params()
        
        # æ”¶é›†æ‰€æœ‰æ•¸æ“š
        comparison_data = []
        
        # ç²å–æ‰€æœ‰å¯¦é©—æª”æ¡ˆ
        exp_files = list(self.exp_dir.glob("*.csv"))
        
        for exp_file in exp_files:
            filename = exp_file.name
            
            row = {
                'filename': filename,
                'basic_correlation': self.basic_results.get(filename, {}).get('correlation', np.nan),
                'advanced_correlation': self.advanced_results.get(filename, {}).get('correlation', np.nan),
                'ml_correlation': ml_correlations.get(filename, {}).get('correlation', np.nan)
            }
            
            comparison_data.append(row)
        
        df = pd.DataFrame(comparison_data)
        
        # è¨ˆç®—æ”¹é€²åº¦
        df['basic_to_advanced'] = df['advanced_correlation'] - df['basic_correlation']
        df['basic_to_ml'] = df['ml_correlation'] - df['basic_correlation']
        df['advanced_to_ml'] = df['ml_correlation'] - df['advanced_correlation']
        
        return df, ml_correlations
    
    def create_visualization(self, df):
        """å‰µå»ºå¯è¦–åŒ–åœ–è¡¨"""
        print("ğŸ¨ å‰µå»ºå¯è¦–åŒ–åœ–è¡¨...")
        
        # å‰µå»ºç¶œåˆæ¯”è¼ƒåœ–
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ç´„ç‘Ÿå¤«æ£®çµåˆ†ææ–¹æ³•ç¶œåˆæ€§èƒ½æ¯”è¼ƒ', fontsize=16, fontweight='bold')
        
        # 1. ç›¸é—œä¿‚æ•¸æ¯”è¼ƒï¼ˆæ¢å½¢åœ–ï¼‰
        ax = axes[0, 0]
        x = np.arange(len(df))
        width = 0.25
        
        ax.bar(x - width, df['basic_correlation'], width, label='Basic Model', alpha=0.8, color='blue')
        ax.bar(x, df['advanced_correlation'], width, label='Advanced Physics Model', alpha=0.8, color='red')
        ax.bar(x + width, df['ml_correlation'], width, label='ML Optimized Model', alpha=0.8, color='green')
        
        ax.set_xlabel('Experimental Files')
        ax.set_ylabel('Correlation Coefficient')
        ax.set_title('Correlation Coefficient Comparison')
        ax.set_xticks(x)
        ax.set_xticklabels([f.replace('.csv', '') for f in df['filename']], rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)
        
        # 2. æ”¹é€²åº¦åˆ†æï¼ˆæ¢å½¢åœ–ï¼‰
        ax = axes[0, 1]
        ax.bar(x - width/2, df['basic_to_advanced'], width, label='Basicâ†’Advanced', alpha=0.8, color='orange')
        ax.bar(x + width/2, df['basic_to_ml'], width, label='Basicâ†’ML', alpha=0.8, color='purple')
        
        ax.set_xlabel('Experimental Files')
        ax.set_ylabel('Correlation Improvement')
        ax.set_title('Method Improvement Effect')
        ax.set_xticks(x)
        ax.set_xticklabels([f.replace('.csv', '') for f in df['filename']], rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)
        
        # 3. æ•£é»åœ–æ¯”è¼ƒ
        ax = axes[0, 2]
        valid_mask = ~(np.isnan(df['basic_correlation']) | np.isnan(df['ml_correlation']))
        if valid_mask.sum() > 0:
            ax.scatter(df.loc[valid_mask, 'basic_correlation'], 
                      df.loc[valid_mask, 'ml_correlation'], 
                      alpha=0.7, s=100, color='green')
            
            # æ·»åŠ å°è§’ç·š
            min_val = min(df.loc[valid_mask, 'basic_correlation'].min(), 
                         df.loc[valid_mask, 'ml_correlation'].min())
            max_val = max(df.loc[valid_mask, 'basic_correlation'].max(), 
                         df.loc[valid_mask, 'ml_correlation'].max())
            ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)
            
            ax.set_xlabel('åŸºç¤æ¨¡å‹ç›¸é—œä¿‚æ•¸')
            ax.set_ylabel('MLå„ªåŒ–æ¨¡å‹ç›¸é—œä¿‚æ•¸')
            ax.set_title('åŸºç¤ vs MLå„ªåŒ– æ•£é»åœ–')
            ax.grid(True, alpha=0.3)
        
        # 4. çµ±è¨ˆæ‘˜è¦ï¼ˆç›´æ–¹åœ–ï¼‰
        ax = axes[1, 0]
        methods = ['åŸºç¤æ¨¡å‹', 'é€²éšç‰©ç†æ¨¡å‹', 'MLå„ªåŒ–æ¨¡å‹']
        means = [df['basic_correlation'].mean(), 
                df['advanced_correlation'].mean(), 
                df['ml_correlation'].mean()]
        stds = [df['basic_correlation'].std(), 
               df['advanced_correlation'].std(), 
               df['ml_correlation'].std()]
        
        x_pos = np.arange(len(methods))
        bars = ax.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.8, 
                     color=['blue', 'red', 'green'])
        
        ax.set_xlabel('åˆ†ææ–¹æ³•')
        ax.set_ylabel('å¹³å‡ç›¸é—œä¿‚æ•¸')
        ax.set_title('æ–¹æ³•æ€§èƒ½çµ±è¨ˆæ‘˜è¦')
        ax.set_xticks(x_pos)
        ax.set_xticklabels(methods)
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar, mean, std in zip(bars, means, stds):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.01,
                   f'{mean:.3f}Â±{std:.3f}', ha='center', va='bottom', fontsize=9)
        
        # 5. ç†±åœ–æ¯”è¼ƒ
        ax = axes[1, 1]
        correlation_matrix = df[['basic_correlation', 'advanced_correlation', 'ml_correlation']].T
        correlation_matrix.columns = [f.replace('.csv', '') for f in df['filename']]
        
        im = ax.imshow(correlation_matrix.values, cmap='RdBu_r', aspect='auto', vmin=-0.2, vmax=0.2)
        ax.set_xticks(range(len(correlation_matrix.columns)))
        ax.set_xticklabels(correlation_matrix.columns, rotation=45, ha='right')
        ax.set_yticks(range(len(correlation_matrix.index)))
        ax.set_yticklabels(['Basic', 'Advanced', 'ML'])
        ax.set_title('Correlation Coefficient Heatmap')
        
        # æ·»åŠ é¡è‰²æ¢
        cbar = plt.colorbar(im, ax=ax)
        cbar.set_label('Correlation Coefficient')
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for i in range(len(correlation_matrix.index)):
            for j in range(len(correlation_matrix.columns)):
                text = ax.text(j, i, f'{correlation_matrix.iloc[i, j]:.3f}',
                             ha="center", va="center", color="black", fontsize=8)
        
        # 6. æ”¹é€²å¹…åº¦æ’åº
        ax = axes[1, 2]
        improvement_df = df[['filename', 'basic_to_ml']].sort_values('basic_to_ml', ascending=True)
        y_pos = np.arange(len(improvement_df))
        
        colors = ['red' if x < 0 else 'green' for x in improvement_df['basic_to_ml']]
        bars = ax.barh(y_pos, improvement_df['basic_to_ml'], color=colors, alpha=0.7)
        
        ax.set_yticks(y_pos)
        ax.set_yticklabels([f.replace('.csv', '') for f in improvement_df['filename']])
        ax.set_xlabel('ç›¸é—œä¿‚æ•¸æ”¹é€²åº¦')
        ax.set_title('MLå„ªåŒ–æ”¹é€²å¹…åº¦æ’åº')
        ax.grid(True, alpha=0.3)
        ax.axvline(x=0, color='k', linestyle='--', alpha=0.5)
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–è¡¨
        output_file = self.results_dir / "comprehensive_performance_comparison.png"
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        print(f"âœ… ç¶œåˆæ¯”è¼ƒåœ–è¡¨å·²ä¿å­˜è‡³: {output_file}")
        
        plt.show()
        
        return output_file
    
    def generate_comprehensive_report(self, df, ml_correlations):
        """ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š"""
        print("ğŸ“ ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š...")
        
        timestamp = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
        
        report = f"""# ç´„ç‘Ÿå¤«æ£®çµæ•¸æ“šåˆ†æç¶œåˆæ€§èƒ½æ¯”è¼ƒå ±å‘Š

ç”Ÿæˆæ™‚é–“: {timestamp}

## åŸ·è¡Œæ‘˜è¦

æœ¬å ±å‘Šæ¯”è¼ƒäº†ä¸‰ç¨®ä¸åŒçš„ç´„ç‘Ÿå¤«æ£®çµæ•¸æ“šåˆ†ææ–¹æ³•ï¼š
1. **åŸºç¤æ¨¡å‹**: æ¨™æº–ç´„ç‘Ÿå¤«æ£®çµç‰©ç†æ¨¡å‹
2. **é€²éšç‰©ç†æ¨¡å‹**: åŒ…å«æº«åº¦æ•ˆæ‡‰ã€éç·šæ€§æ•ˆæ‡‰çš„é€²éšç‰©ç†æ¨¡å‹  
3. **MLå„ªåŒ–æ¨¡å‹**: åŸºæ–¼æ©Ÿå™¨å­¸ç¿’å„ªåŒ–åƒæ•¸çš„æ¨¡å‹

## æ€§èƒ½çµ±è¨ˆæ‘˜è¦

### å¹³å‡ç›¸é—œä¿‚æ•¸
- åŸºç¤æ¨¡å‹: {df['basic_correlation'].mean():.4f} Â± {df['basic_correlation'].std():.4f}
- é€²éšç‰©ç†æ¨¡å‹: {df['advanced_correlation'].mean():.4f} Â± {df['advanced_correlation'].std():.4f}
- MLå„ªåŒ–æ¨¡å‹: {df['ml_correlation'].mean():.4f} Â± {df['ml_correlation'].std():.4f}

### æ”¹é€²æ•ˆæœåˆ†æ
- åŸºç¤â†’é€²éšç‰©ç†: å¹³å‡æ”¹é€² {df['basic_to_advanced'].mean():.4f}
- åŸºç¤â†’MLå„ªåŒ–: å¹³å‡æ”¹é€² {df['basic_to_ml'].mean():.4f}
- é€²éšâ†’MLå„ªåŒ–: å¹³å‡æ”¹é€² {df['advanced_to_ml'].mean():.4f}

## è©³ç´°çµæœ

| å¯¦é©—æª”æ¡ˆ | åŸºç¤æ¨¡å‹ | é€²éšç‰©ç†æ¨¡å‹ | MLå„ªåŒ–æ¨¡å‹ | åŸºç¤â†’MLæ”¹é€² |
|---------|---------|-------------|-----------|------------|
"""
        
        for _, row in df.iterrows():
            report += f"| {row['filename'].replace('.csv', '')} | {row['basic_correlation']:.4f} | {row['advanced_correlation']:.4f} | {row['ml_correlation']:.4f} | {row['basic_to_ml']:.4f} |\n"
        
        # æ·»åŠ æœ€ä½³å’Œæœ€å·®è¡¨ç¾åˆ†æ
        best_basic = df.loc[df['basic_correlation'].idxmax()]
        best_advanced = df.loc[df['advanced_correlation'].idxmax()]
        best_ml = df.loc[df['ml_correlation'].idxmax()]
        
        report += f"""
## æ€§èƒ½äº®é»

### æœ€ä½³è¡¨ç¾
- **åŸºç¤æ¨¡å‹æœ€ä½³**: {best_basic['filename']} (r = {best_basic['basic_correlation']:.4f})
- **é€²éšç‰©ç†æ¨¡å‹æœ€ä½³**: {best_advanced['filename']} (r = {best_advanced['advanced_correlation']:.4f})
- **MLå„ªåŒ–æ¨¡å‹æœ€ä½³**: {best_ml['filename']} (r = {best_ml['ml_correlation']:.4f})

### æ”¹é€²å¹…åº¦æœ€å¤§
"""
        
        max_improvement = df.loc[df['basic_to_ml'].idxmax()]
        min_improvement = df.loc[df['basic_to_ml'].idxmin()]
        
        report += f"""- **æœ€å¤§æ”¹é€²**: {max_improvement['filename']} (+{max_improvement['basic_to_ml']:.4f})
- **æœ€å¤§é€€åŒ–**: {min_improvement['filename']} ({min_improvement['basic_to_ml']:.4f})

## MLå„ªåŒ–åƒæ•¸åˆ†æ

"""
        
        for filename, data in ml_correlations.items():
            if 'parameters' in data:
                params = data['parameters']
                report += f"""### {filename.replace('.csv', '')}
- é æ¸¬ç›¸é—œä¿‚æ•¸: {data['correlation']:.4f}
- å„ªåŒ–åƒæ•¸:
  - Ic_base: {params['Ic_base']:.2e}
  - field_scale: {params['field_scale']:.2e}
  - phase_offset: {params['phase_offset']:.4f}
  - asymmetry: {params['asymmetry']:.4f}
  - noise_level: {params.get('noise_level', 'N/A')}

"""
        
        report += f"""
## çµè«–èˆ‡å»ºè­°

### æ–¹æ³•æ•ˆæœè©•ä¼°
1. **é€²éšç‰©ç†æ¨¡å‹** ç›¸æ¯”åŸºç¤æ¨¡å‹å¹³å‡æ”¹é€² {df['basic_to_advanced'].mean():.4f}
2. **MLå„ªåŒ–æ¨¡å‹** ç›¸æ¯”åŸºç¤æ¨¡å‹å¹³å‡æ”¹é€² {df['basic_to_ml'].mean():.4f}
3. **æœ€ä½³æ•´é«”è¡¨ç¾**: {"MLå„ªåŒ–æ¨¡å‹" if df['ml_correlation'].mean() > df['advanced_correlation'].mean() else "é€²éšç‰©ç†æ¨¡å‹"}

### æœªä¾†ç™¼å±•æ–¹å‘
1. **æ··åˆæ¨¡å‹**: çµåˆé€²éšç‰©ç†æ¨¡å‹å’ŒMLå„ªåŒ–çš„å„ªé»
2. **æ·±åº¦å­¸ç¿’**: æ¢ç´¢ç¥ç¶“ç¶²è·¯åœ¨æ¨¡å¼è­˜åˆ¥æ–¹é¢çš„æ½›åŠ›
3. **å¤šæº«åº¦å»ºæ¨¡**: æ“´å±•åˆ°æº«åº¦ç›¸é—œæ•ˆæ‡‰çš„åˆ†æ
4. **å¯¦æ™‚å„ªåŒ–**: é–‹ç™¼è‡ªé©æ‡‰åƒæ•¸èª¿æ•´ç³»çµ±
5. **æ›´å¤šå¯¦é©—æ•¸æ“š**: æ”¶é›†æ›´å¤§è¦æ¨¡çš„å¯¦é©—æ•¸æ“šé›†ä»¥æ”¹å–„æ¨¡å‹è¨“ç·´

### æŠ€è¡“å»ºè­°
- å°æ–¼é«˜é›œè¨Šæ•¸æ“šï¼Œæ¨è–¦ä½¿ç”¨MLå„ªåŒ–æ¨¡å‹
- å°æ–¼ç‰©ç†ç†è§£éœ€æ±‚ï¼Œæ¨è–¦ä½¿ç”¨é€²éšç‰©ç†æ¨¡å‹
- å°æ–¼å¿«é€Ÿåˆ†æï¼ŒåŸºç¤æ¨¡å‹ä»ç„¶å…·æœ‰åƒ¹å€¼

---
*å ±å‘Šç”±ç¶œåˆæ€§èƒ½æ¯”è¼ƒç³»çµ±è‡ªå‹•ç”Ÿæˆ*
"""
        
        # ä¿å­˜å ±å‘Š
        report_file = self.results_dir / "comprehensive_performance_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… ç¶œåˆåˆ†æå ±å‘Šå·²ä¿å­˜è‡³: {report_file}")
        
        return report_file

def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    print("=== ç´„ç‘Ÿå¤«æ£®çµç¶œåˆæ€§èƒ½æ¯”è¼ƒç³»çµ± ===\n")
    
    base_dir = "/Users/albert-mac/Code/GitHub/Josephson"
    comparator = ComprehensiveComparator(base_dir)
    
    # åŸ·è¡Œç¶œåˆæ¯”è¼ƒ
    df, ml_correlations = comparator.create_comprehensive_comparison()
    
    # å‰µå»ºå¯è¦–åŒ–
    chart_file = comparator.create_visualization(df)
    
    # ç”Ÿæˆå ±å‘Š
    report_file = comparator.generate_comprehensive_report(df, ml_correlations)
    
    # ä¿å­˜æ¯”è¼ƒæ•¸æ“š
    comparison_file = comparator.results_dir / "comprehensive_comparison_data.json"
    comparison_data = {
        'comparison_table': df.to_dict('records'),
        'ml_correlations': ml_correlations,
        'summary_stats': {
            'basic_mean': float(df['basic_correlation'].mean()),
            'advanced_mean': float(df['advanced_correlation'].mean()),
            'ml_mean': float(df['ml_correlation'].mean()),
            'basic_std': float(df['basic_correlation'].std()),
            'advanced_std': float(df['advanced_correlation'].std()),
            'ml_std': float(df['ml_correlation'].std())
        }
    }
    
    with open(comparison_file, 'w', encoding='utf-8') as f:
        json.dump(comparison_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… æ¯”è¼ƒæ•¸æ“šå·²ä¿å­˜è‡³: {comparison_file}")
    print("\nğŸ‰ ç¶œåˆæ€§èƒ½æ¯”è¼ƒåˆ†æå®Œæˆï¼")
    
    # è¼¸å‡ºé—œéµçµ±è¨ˆ
    print(f"\nğŸ“Š é—œéµçµ±è¨ˆ:")
    print(f"   åŸºç¤æ¨¡å‹å¹³å‡ç›¸é—œä¿‚æ•¸: {df['basic_correlation'].mean():.4f}")
    print(f"   é€²éšç‰©ç†æ¨¡å‹å¹³å‡ç›¸é—œä¿‚æ•¸: {df['advanced_correlation'].mean():.4f}")
    print(f"   MLå„ªåŒ–æ¨¡å‹å¹³å‡ç›¸é—œä¿‚æ•¸: {df['ml_correlation'].mean():.4f}")
    print(f"   æœ€ä½³æ•´é«”æ–¹æ³•: {'MLå„ªåŒ–æ¨¡å‹' if df['ml_correlation'].mean() > df['advanced_correlation'].mean() else 'é€²éšç‰©ç†æ¨¡å‹'}")

if __name__ == "__main__":
    main()
