"""
é€±æœŸæ€§åˆ†æžå·¥å…·

æä¾›å¤šç¨®é€±æœŸæª¢æ¸¬æ–¹æ³•ï¼ŒåŒ…æ‹¬ Lomb-Scargle é€±æœŸåœ–ã€FFT åˆ†æžç­‰ã€‚
é©ç”¨æ–¼ Josephson çµç£é€šéŸ¿æ‡‰çš„é€±æœŸæ€§ç‰¹å¾µæå–ã€‚
"""

import numpy as np
from astropy.timeseries import LombScargle
from scipy import signal
from .statistics import ModelStatistics

def enhanced_lomb_scargle_analysis(phi_ext, current, errors=None, detrend_order=2):
    """
    å¢žå¼·ç‰ˆ Lomb-Scargle é€±æœŸåˆ†æž
    
    Parameters:
    -----------
    phi_ext : array-like
        å¤–éƒ¨ç£é€šé™£åˆ—
    current : array-like  
        é›»æµéŸ¿æ‡‰é™£åˆ—
    errors : array-like, optional
        æ¸¬é‡èª¤å·®é™£åˆ—
    detrend_order : int
        åŽ»è¶¨å‹¢å¤šé …å¼éšŽæ•¸
    
    Returns:
    --------
    dict : åŒ…å«åˆ†æžçµæžœçš„å­—å…¸
    """
    print(f"ðŸ” åŸ·è¡Œ Lomb-Scargle é€±æœŸåˆ†æž")
    
    # æ•¸æ“šé è™•ç†
    phi_ext = np.array(phi_ext)
    current = np.array(current)
    
    if errors is None:
        errors = np.std(current) * 0.1 * np.ones_like(current)
    
    # åŽ»è¶¨å‹¢åŒ–
    detrended_current = current.copy()
    trend_coeffs = None
    
    if detrend_order > 0:
        trend_coeffs = np.polyfit(phi_ext, current, detrend_order)
        trend = np.polyval(trend_coeffs, phi_ext)
        detrended_current = current - trend
        print(f"âœ… æ‡‰ç”¨ {detrend_order} éšŽå¤šé …å¼åŽ»è¶¨å‹¢åŒ–")
    
    # å»ºç«‹ Lomb-Scargle ç‰©ä»¶
    ls = LombScargle(phi_ext, detrended_current, dy=errors,
                    fit_mean=True, center_data=True)
    
    # è¨ˆç®—é »çŽ‡ç¯„åœ
    phi_span = phi_ext.max() - phi_ext.min()
    min_freq = 0.5 / phi_span
    median_dphi = np.median(np.diff(np.sort(phi_ext)))
    max_freq = 0.5 / median_dphi
    
    print(f"é »çŽ‡æœç´¢ç¯„åœ: {min_freq:.2e} åˆ° {max_freq:.2e}")
    
    # è¨ˆç®—é€±æœŸåœ–
    frequency, power = ls.autopower(
        minimum_frequency=min_freq,
        maximum_frequency=max_freq,
        samples_per_peak=20
    )
    
    # å°‹æ‰¾æœ€ä½³é »çŽ‡
    best_idx = np.argmax(power)
    best_frequency = frequency[best_idx]
    best_power = power[best_idx]
    best_period = 1.0 / best_frequency
    
    # è¨ˆç®—çµ±è¨ˆé¡¯è‘—æ€§
    try:
        fap = ls.false_alarm_probability(best_power, method='baluev')
    except:
        fap = None
    
    # è¨ˆç®—æ¨¡åž‹åƒæ•¸
    model_params = ls.model_parameters(best_frequency)
    amplitude = np.sqrt(model_params[0]**2 + model_params[1]**2)
    phase = np.arctan2(model_params[1], model_params[0])
    offset = ls.offset()
    
    # ç”Ÿæˆæ“¬åˆæ¨¡åž‹
    ls_model_detrended = ls.model(phi_ext, best_frequency)
    
    if trend_coeffs is not None:
        ls_model_full = ls_model_detrended + trend
    else:
        ls_model_full = ls_model_detrended
    
    # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
    stats = ModelStatistics(
        y_true=current,
        y_pred=ls_model_full,
        n_params=3,
        model_name="Lomb-Scargle"
    )
    
    # å°‹æ‰¾å…¶ä»–é¡¯è‘—å³°å€¼
    significant_peaks = find_significant_peaks(frequency, power, n_peaks=5)
    
    results = {
        'frequency': frequency,
        'power': power,
        'best_frequency': best_frequency,
        'best_period': best_period,
        'best_power': best_power,
        'amplitude': amplitude,
        'phase': phase,
        'offset': offset,
        'false_alarm_probability': fap,
        'ls_model': ls_model_full,
        'detrended_current': detrended_current,
        'trend_coeffs': trend_coeffs,
        'significant_peaks': significant_peaks,
        'statistics': stats.get_summary_dict(),
        'ls_object': ls
    }
    
    print(f"âœ… æª¢æ¸¬åˆ°ä¸»è¦é »çŽ‡: {best_frequency:.2e}")
    print(f"   å°æ‡‰é€±æœŸ: {best_period:.2e}")
    print(f"   æœ€å¤§åŠŸçŽ‡: {best_power:.4f}")
    if fap is not None:
        print(f"   è™›è­¦æ¦‚çŽ‡: {fap:.2e}")
    
    return results

def fft_period_analysis(phi_ext, current, window='hann'):
    """
    FFT é€±æœŸåˆ†æž
    
    Parameters:
    -----------
    phi_ext : array-like
        å¤–éƒ¨ç£é€šé™£åˆ—
    current : array-like
        é›»æµéŸ¿æ‡‰é™£åˆ—
    window : str
        çª—å‡½æ•¸é¡žåž‹
    
    Returns:
    --------
    dict : FFT åˆ†æžçµæžœ
    """
    print(f"âš¡ åŸ·è¡Œ FFT é€±æœŸåˆ†æž")
    
    phi_ext = np.array(phi_ext)
    current = np.array(current)
    
    # ç¢ºä¿ç­‰é–“è·ï¼ˆæ’å€¼å¦‚æžœéœ€è¦ï¼‰
    if not np.allclose(np.diff(phi_ext), np.diff(phi_ext)[0], rtol=1e-3):
        print("âš ï¸ ç£é€šæ•¸æ“šä¸ç­‰é–“è·ï¼ŒåŸ·è¡Œæ’å€¼")
        phi_uniform = np.linspace(phi_ext.min(), phi_ext.max(), len(phi_ext))
        current = np.interp(phi_uniform, phi_ext, current)
        phi_ext = phi_uniform
    
    # æ‡‰ç”¨çª—å‡½æ•¸
    if window:
        window_func = signal.get_window(window, len(current))
        windowed_current = current * window_func
        print(f"âœ… æ‡‰ç”¨ {window} çª—å‡½æ•¸")
    else:
        windowed_current = current
    
    # è¨ˆç®— FFT
    fft_values = np.fft.fft(windowed_current)
    fft_power = np.abs(fft_values)**2
    
    # é »çŽ‡é™£åˆ—
    dphi = np.mean(np.diff(phi_ext))
    frequencies = np.fft.fftfreq(len(current), dphi)
    
    # åªå–æ­£é »çŽ‡éƒ¨åˆ†
    positive_mask = frequencies > 0
    frequencies = frequencies[positive_mask]
    fft_power = fft_power[positive_mask]
    
    # å°‹æ‰¾ä¸»è¦é »çŽ‡
    dominant_idx = np.argmax(fft_power)
    dominant_frequency = frequencies[dominant_idx]
    dominant_power = fft_power[dominant_idx]
    
    # è¨ˆç®—åŠŸçŽ‡æ¯”ï¼ˆä¸»å³°èˆ‡å¹³å‡åŠŸçŽ‡çš„æ¯”å€¼ï¼‰
    mean_power = np.mean(fft_power)
    power_ratio = dominant_power / mean_power
    
    # å°‹æ‰¾å‰å¹¾å€‹å³°å€¼
    peak_indices = signal.find_peaks(fft_power, height=mean_power*2)[0]
    top_peaks = peak_indices[np.argsort(fft_power[peak_indices])[-5:]]
    
    results = {
        'frequencies': frequencies,
        'power_spectrum': fft_power,
        'dominant_frequency': dominant_frequency,
        'dominant_period': 1.0 / dominant_frequency,
        'dominant_power': dominant_power,
        'power_ratio': power_ratio,
        'peak_frequencies': frequencies[top_peaks],
        'peak_powers': fft_power[top_peaks],
        'window_used': window
    }
    
    print(f"âœ… ä¸»è¦é »çŽ‡: {dominant_frequency:.2e}")
    print(f"   å°æ‡‰é€±æœŸ: {1.0/dominant_frequency:.2e}")
    print(f"   åŠŸçŽ‡æ¯”: {power_ratio:.2f}")
    
    return results

def find_significant_peaks(frequency, power, n_peaks=10):
    """
    å°‹æ‰¾åŠŸçŽ‡è­œä¸­çš„é¡¯è‘—å³°å€¼
    
    Parameters:
    -----------
    frequency : array-like
        é »çŽ‡é™£åˆ—
    power : array-like
        åŠŸçŽ‡é™£åˆ—
    n_peaks : int
        è¿”å›žçš„å³°å€¼æ•¸é‡
    
    Returns:
    --------
    list : é¡¯è‘—å³°å€¼çš„ä¿¡æ¯
    """
    mean_power = np.mean(power)
    std_power = np.std(power)
    threshold = mean_power + 2 * std_power
    
    # å°‹æ‰¾å³°å€¼
    peaks, properties = signal.find_peaks(
        power, 
        height=threshold, 
        distance=len(power)//50  # æœ€å°é–“è·
    )
    
    if len(peaks) == 0:
        return []
    
    # æŒ‰åŠŸçŽ‡æŽ’åº
    peak_powers = power[peaks]
    sorted_indices = np.argsort(peak_powers)[::-1]
    top_peaks = peaks[sorted_indices[:n_peaks]]
    
    significant_peaks = []
    for peak_idx in top_peaks:
        significant_peaks.append({
            'frequency': frequency[peak_idx],
            'period': 1.0 / frequency[peak_idx],
            'power': power[peak_idx],
            'significance': power[peak_idx] / mean_power
        })
    
    return significant_peaks

def autocorrelation_analysis(phi_ext, current, max_lag=None):
    """
    è‡ªç›¸é—œå‡½æ•¸åˆ†æž
    
    Parameters:
    -----------
    phi_ext : array-like
        å¤–éƒ¨ç£é€šé™£åˆ—
    current : array-like
        é›»æµéŸ¿æ‡‰é™£åˆ—
    max_lag : int, optional
        æœ€å¤§æ»¯å¾Œæ•¸
    
    Returns:
    --------
    dict : è‡ªç›¸é—œåˆ†æžçµæžœ
    """
    print(f"ðŸ”„ åŸ·è¡Œè‡ªç›¸é—œåˆ†æž")
    
    current = np.array(current)
    n = len(current)
    
    if max_lag is None:
        max_lag = n // 4
    
    # è¨ˆç®—è‡ªç›¸é—œ
    autocorr = np.correlate(current - np.mean(current), 
                           current - np.mean(current), 
                           mode='full')
    
    # æ­¸ä¸€åŒ–
    autocorr = autocorr / autocorr[n-1]
    
    # å–æ­£æ»¯å¾Œéƒ¨åˆ†
    autocorr = autocorr[n-1:n-1+max_lag]
    lags = np.arange(max_lag)
    
    # å°‹æ‰¾è‡ªç›¸é—œå³°å€¼ï¼ˆé™¤äº†é›¶æ»¯å¾Œï¼‰
    if len(autocorr) > 1:
        peaks, _ = signal.find_peaks(autocorr[1:], height=0.1)
        peaks = peaks + 1  # ä¿®æ­£ç´¢å¼•
    else:
        peaks = []
    
    results = {
        'lags': lags,
        'autocorrelation': autocorr,
        'peaks': peaks,
        'max_autocorr_lag': lags[np.argmax(autocorr[1:])+1] if len(autocorr) > 1 else 0
    }
    
    if len(peaks) > 0:
        first_peak_lag = peaks[0]
        phi_spacing = np.mean(np.diff(phi_ext))
        estimated_period = first_peak_lag * phi_spacing
        print(f"âœ… ä¼°è¨ˆé€±æœŸ: {estimated_period:.2e} (å¾žè‡ªç›¸é—œ)")
    
    return results